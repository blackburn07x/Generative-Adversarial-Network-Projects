{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport io\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.initializers import RandomNormal\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tensorflow.keras.backend as K\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow_addons as tfa\nfrom IPython import display\nautotune = tf.data.AUTOTUNE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-19T12:43:24.035149Z","iopub.execute_input":"2023-03-19T12:43:24.036081Z","iopub.status.idle":"2023-03-19T12:43:24.043088Z","shell.execute_reply.started":"2023-03-19T12:43:24.036027Z","shell.execute_reply":"2023-03-19T12:43:24.041950Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Read the data","metadata":{}},{"cell_type":"code","source":"X1 = os.listdir(\"/kaggle/input/cyclegan/horse2zebra/horse2zebra/trainA\")\nX1 = [os.path.join(\"/kaggle/input/cyclegan/horse2zebra/horse2zebra/trainA\", x) for x in X1][:1000]\n\nX2 = os.listdir(\"/kaggle/input/cyclegan/horse2zebra/horse2zebra/trainB\")\nX2 = [os.path.join(\"/kaggle/input/cyclegan/horse2zebra/horse2zebra/trainB\", x) for x in X2][:1000]","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:02:32.324787Z","iopub.execute_input":"2023-03-19T13:02:32.325495Z","iopub.status.idle":"2023-03-19T13:02:32.356839Z","shell.execute_reply.started":"2023-03-19T13:02:32.325458Z","shell.execute_reply":"2023-03-19T13:02:32.355791Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#read images\ndef read_images(file_paths):\n    imgs = []\n    for file_path in tqdm(file_paths):\n        img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (128,128))\n        img = img.astype(np.float32)\n        img = (img - 127.5) / 127.5\n        imgs.append(img)\n    return np.array(imgs)\n\nvan = read_images(X1)\nreal = read_images(X2)\n\ndef denormalize_img(img):\n    return ((img * 127.5) + 127.5).astype(np.uint8)\n\n\ndef mini_batches_(X, Y, batch_size=64):\n    \"\"\"\n    function to produce minibatches for training\n    :param X: input placeholder\n    :param Y: mask placeholder\n    :param batch_size: size of each batch\n    :return:\n    minibatches for training\n    \n    \"\"\"\n    batches= []\n    train_length = len(X)\n    num_batches = int(np.floor(train_length / batch_size))\n    for i in tqdm(range(num_batches)):\n        batch_x = X[i * batch_size: i * batch_size + batch_size]\n        batch_y = Y[i * batch_size: i * batch_size + batch_size]\n        batch_x = read_images(batch_x)\n        batch_y = read_images(batch_y)\n        batches.append([batch_x,batch_y])\n    return batches\n#gan_dataset = mini_batches_(X1, X2, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:02:34.386718Z","iopub.execute_input":"2023-03-19T13:02:34.387436Z","iopub.status.idle":"2023-03-19T13:02:42.722211Z","shell.execute_reply.started":"2023-03-19T13:02:34.387384Z","shell.execute_reply":"2023-03-19T13:02:42.720817Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [00:04<00:00, 234.81it/s]\n100%|██████████| 1000/1000 [00:03<00:00, 254.51it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"van.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T12:43:33.120688Z","iopub.execute_input":"2023-03-19T12:43:33.121678Z","iopub.status.idle":"2023-03-19T12:43:33.133832Z","shell.execute_reply.started":"2023-03-19T12:43:33.121636Z","shell.execute_reply":"2023-03-19T12:43:33.132787Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(600, 128, 128, 3)"},"metadata":{}}]},{"cell_type":"code","source":"#read images\ndef read_images(file_paths):\n    imgs = []\n    for file_path in file_paths:\n        img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (128,128))\n        img = img.astype(np.float32)\n        img = (img - 127.5) / 127.5\n        imgs.append(img)\n    return np.array(imgs)\n\ndef denormalize_img(img):\n    return ((img * 127.5) + 127.5).astype(np.uint8)\n\ndef mini_batches_(X, batch_size=64):\n    \n    \"\"\"function to produce minibatches for training\n    :param X: input placeholder\n    :param Y: mask placeholder\n    :param batch_size: size of each batch\n    :return:\n    minibatches for training\"\"\"\n    \n    \n    images_batch = []\n    train_length = len(X)\n    num_batches = int(np.floor(train_length / batch_size))\n    for i in tqdm(range(num_batches)):\n        batch_x = X[i * batch_size: i * batch_size + batch_size]\n        batch_x = read_images(batch_x)\n        images_batch.append(batch_x)\n    return images_batch\nvan = mini_batches_(X1, batch_size=1)\nreal = mini_batches_(X2, batch_size=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zip((van,real))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize the examples\nfor i in range(10):\n    plt.figure(figsize=(9, 9))\n    plt.subplot(231)\n    plt.title(\"\\n\\nVangogh\")\n    plt.imshow(denormalize_img(van[i]))\n    plt.axis('off')\n    plt.subplot(232)\n    plt.imshow(denormalize_img(real[i]))\n    plt.title(\"\\n\\nReal Photo\")\n    plt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CycleGAN","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\ndef conv2d(x, filter_size, filters, stride = 1, padding = 'same'):\n    x = tf.keras.layers.Conv2D(filters,(filter_size,filter_size), strides =(stride,stride), padding = padding, kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02))(x)\n    return x\n\ndef batch_norm(x):\n    x = tf.keras.layers.BatchNormalization()(x)\n    return x\n\ndef instance_norm(x):\n    return tfa.layers.InstanceNormalization(gamma_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02))(x)\n\ndef relu(x):\n    return tf.keras.activations.relu(x, alpha = 0.2)\n\ndef leaky_relu(x):\n    return tf.keras.layers.LeakyReLU(alpha = 0.2)(x)\n\nclass ReflectionPadding(tf.keras.layers.Layer):\n    def __init__(self, dim_padding = (1,1)):\n        super(ReflectionPadding, self).__init__()\n        self.padding = dim_padding\n    def call(self, tensor):\n        x = tf.pad(tensor, [[0,0], [self.padding[1], self.padding[1]], [self.padding[0], self.padding[0]], [0,0]], \n                  mode = \"REFLECT\")\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:02:42.725621Z","iopub.execute_input":"2023-03-19T13:02:42.726151Z","iopub.status.idle":"2023-03-19T13:02:42.738797Z","shell.execute_reply.started":"2023-03-19T13:02:42.726107Z","shell.execute_reply":"2023-03-19T13:02:42.737733Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### CycleGAN Network","metadata":{}},{"cell_type":"code","source":"class CycleGAN(tf.keras.Model):\n    def __init__(self):\n        super(CycleGAN, self).__init__()\n        \n        self.gen_a = self.generator()\n        self.gen_b = self.generator()\n        \n        self.disc_a = self.discriminator()\n        self.disc_b = self.discriminator()\n        \n     \n        \n        self.kernel_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n        self.mse = tf.keras.losses.MeanSquaredError()\n        self.cycle_loss = tf.keras.losses.MeanAbsoluteError()\n        self.identity_loss = tf.keras.losses.MeanAbsoluteError()\n    \n    def resnet_block(self, prev_input):\n        x = prev_input\n        dims = x.shape[-1]\n        \n        #block1\n        #using reflection padding as described in the paper\n        x = ReflectionPadding()(x)\n        x = conv2d(x, 3, dims, stride = 1, padding = \"valid\")\n        x = instance_norm(x)\n        x = tf.keras.activations.relu(x, alpha = 0.2)\n        \n        #block 2\n        x = ReflectionPadding()(x)\n        x = conv2d(x, 3, dims, stride = 1, padding = \"valid\")\n        x = instance_norm(x)\n        x = tf.keras.activations.relu(x, alpha = 0.2)\n        \n        out = tf.keras.layers.add([prev_input, x])\n        return out\n    \n    def conv_transpose_block(self, x, filter_size, filters, stride = 2 , padding = 'same' , norm = True, activation = True):\n        x = tf.keras.layers.Conv2DTranspose(filters, filter_size, strides = (stride,stride), padding =padding)(x)\n        if norm:\n            x = instance_norm(x)\n        if activation:\n            x = tf.keras.activations.relu(x,alpha = 0.2)\n        return x\n    \n    \n    #define generator\n    def generator(self, resnet_blocks = 6, conv_blocks = 2, conv_transpose_block = 2):\n        filters = 64\n        #input layer\n        input_layer = tf.keras.layers.Input(shape = (128,128,3))\n        #generator architecture\n        x = ReflectionPadding(dim_padding = (3,3))(input_layer)\n        x = conv2d(x,7,filters, padding = 'valid')\n        x = instance_norm(x)\n        x = relu(x)\n        \n        #downsampling\n        for _ in range(conv_blocks):\n            filters*=2\n            x = conv2d(x,3,filters,stride = 2)\n            x = instance_norm(x)\n            x = relu(x)\n        \n        #resnet block\n        for _ in range(resnet_blocks):\n            x = self.resnet_block(x)\n        \n        # upsampling block\n        for _ in range(conv_transpose_block):\n            filters//=2\n            x = self.conv_transpose_block(x, 3, filters, stride = 2)\n        \n        #output block\n        x = ReflectionPadding(dim_padding = (3,3))(x)\n        x = conv2d(x, 7, 3, padding = 'valid')\n        out = tf.keras.layers.Activation('tanh')(x)\n        \n        model = tf.keras.Model(inputs = input_layer, outputs = out)\n        return model\n    \n    def discriminator(self):\n        filters = 64\n        input_layer = tf.keras.layers.Input(shape = (128,128,3))\n        #conv1\n        x = conv2d(input_layer, 4,filters,stride = 2, padding = 'same')\n        x = leaky_relu(x)\n        #conv2 c128s2f4\n        x = conv2d(x, 4, filters*2, stride = 2, padding = 'same' )\n        x = instance_norm(x)\n        x = leaky_relu(x)\n        #c256\n        x = conv2d(x,4,filters*4,stride = 2, padding = 'same')\n        x = instance_norm(x)\n        x = leaky_relu(x)\n        #c512\n        x = conv2d(x, 4,filters*8, stride =1, padding = 'same')\n        x = instance_norm(x)\n        x = leaky_relu(x)\n        \n        out = conv2d(x, 4, 1, stride = 1, padding ='same')\n        model = tf.keras.Model(input_layer, out)\n        return model\n    \n    #define losses \n    def gen_adversarial_loss(self, disc_fake_images):\n        loss = self.mse(tf.ones_like(disc_fake_images), disc_fake_images)\n        return loss\n    \n    def disc_adversarial_loss(self, real_images, gen_fake_images):\n        real_images = self.mse(tf.ones_like(real_images), real_images)\n        fake_images = self.mse(tf.zeros_like(gen_fake_images), gen_fake_images)\n        loss = (real_images + fake_images) * 0.5\n        return loss\n    \n    def compile(self, gen_a_opt, gen_b_opt, disc_a_opt, disc_b_opt):\n        super(CycleGAN, self).compile()\n        self.genAopt = gen_a_opt\n        self.genBopt = gen_b_opt\n        \n        self.discAopt = disc_a_opt\n        self.discBopt = disc_b_opt\n        \n        self.gen_loss = self.gen_adversarial_loss\n        self.disc_loss = self.disc_adversarial_loss\n        \n        self.cycle_loss = tf.keras.losses.MeanAbsoluteError()\n        self.identity_loss = tf.keras.losses.MeanAbsoluteError()\n    \n    def train_step(self, gan_dataset):\n        batch_x, batch_y = gan_dataset\n        #print(batch_x.shape, batch_y.shape)\n        with tf.GradientTape(persistent = True) as tape:\n            #get gen_A(van to real)\n            #fake_x\n            fake_y = self.gen_a(batch_x, training = True)\n            fake_x = self.gen_b(batch_y, training = True)\n            #get cycled gen_b -> real to van\n            cycled_x= self.gen_b(fake_y, training = True)\n            #get gen_B(real to van)\n            #get cycled for gen_b\n            cycled_y = self.gen_a(fake_x, training = True)\n            \n            #get identity loss\n            same_y = self.gen_a(batch_y, training = True)\n            same_x = self.gen_b(batch_x, training = True)\n            \n            #get disc output\n            disc_real_x  = self.disc_a(batch_x, training = True)\n            disc_fake_x  = self.disc_a(fake_x, training = True)\n            \n            disc_real_y  = self.disc_b(batch_y, training = True)\n            disc_fake_y  = self.disc_b(fake_y, training = True)\n            \n            #calculating generator loss\n            gen_a_loss  = self.gen_adversarial_loss(disc_fake_y)\n            gen_b_loss  = self.gen_adversarial_loss(disc_fake_x)\n            \n            #calculate identity loss\n            gen_a_identity = self.identity_loss(batch_y, same_y) * 10.0 * 0.5\n            gen_b_identity = self.identity_loss(batch_x, same_x) * 10.0 * 0.5\n            \n            #cycle loss\n            gen_a_cycle = self.cycle_loss(batch_y, cycled_y) * 10.0\n            gen_b_cycle = self.cycle_loss(batch_x, cycled_x) * 10.0\n            \n            #Total disc loss\n            disc_a_loss = self.disc_adversarial_loss(disc_real_x, disc_fake_x)\n            disc_b_loss = self.disc_adversarial_loss(disc_real_y, disc_fake_y)\n            \n            #total gen loss\n            gen_a_loss = gen_a_loss + gen_a_identity + gen_a_cycle\n            gen_b_loss = gen_b_loss + gen_b_identity + gen_b_cycle\n        gen_a_grad = tape.gradient(gen_a_loss, self.gen_a.trainable_variables)\n        gen_b_grad = tape.gradient(gen_b_loss, self.gen_b.trainable_variables)\n        \n        #discriminator weight gradients\n        disc_a_grad = tape.gradient(disc_a_loss, self.disc_a.trainable_variables)\n        disc_b_grad = tape.gradient(disc_b_loss, self.disc_b.trainable_variables)\n        \n        #weight updation\n        self.genAopt.apply_gradients(zip(gen_a_grad, self.gen_a.trainable_variables))\n        self.genBopt.apply_gradients(zip(gen_b_grad, self.gen_b.trainable_variables))\n        \n        self.discAopt.apply_gradients(zip(disc_a_grad, self.disc_a.trainable_variables))\n        self.discBopt.apply_gradients(zip(disc_b_grad, self.disc_b.trainable_variables))\n        \n        return {\n            \"G_loss\": gen_a_loss,\n            \"F_loss\": gen_b_loss,\n            \"D_X_loss\": disc_a_loss,\n            \"D_Y_loss\": disc_b_loss}\n        \n\ngan = CycleGAN()\ngan.compile(tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n           tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5), tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5))","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:02:52.553273Z","iopub.execute_input":"2023-03-19T13:02:52.553656Z","iopub.status.idle":"2023-03-19T13:02:54.405965Z","shell.execute_reply.started":"2023-03-19T13:02:52.553623Z","shell.execute_reply":"2023-03-19T13:02:54.404914Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class GANMonitor(tf.keras.callbacks.Callback):\n    \"\"\"A callback to generate and save images after each epoch\"\"\"\n\n    def __init__(self, num_img=4):\n        self.num_img = num_img\n\n    def on_epoch_end(self, epoch, logs=None):\n        _, ax = plt.subplots(4, 2, figsize=(12, 12))\n        for i in range(4):\n            r = np.random.randint(0,350)\n            img = van[r]\n            img = np.expand_dims(img, axis = 0)\n            prediction = self.model.gen_a(img).numpy()\n            #prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n            img = (img[0] * 127.5 + 127.5).astype(np.uint8)\n\n            ax[i, 0].imshow(img)\n            ax[i, 1].imshow(denormalize_img(prediction[0]))\n            ax[i, 0].set_title(\"Input image\")\n            ax[i, 1].set_title(\"Translated image\")\n            ax[i, 0].axis(\"off\")\n            ax[i, 1].axis(\"off\")\n\n            prediction = tf.keras.preprocessing.image.array_to_img(prediction[0])\n            prediction.save(\n                \"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch + 1)\n            )\n        plt.show()\n        plt.close()\n        \nplotter = GANMonitor()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:02:56.330423Z","iopub.execute_input":"2023-03-19T13:02:56.330803Z","iopub.status.idle":"2023-03-19T13:02:56.341743Z","shell.execute_reply.started":"2023-03-19T13:02:56.330768Z","shell.execute_reply":"2023-03-19T13:02:56.340612Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"gan.fit(x = van, y = real,epochs=100,\n        batch_size = 1,\n    callbacks=[plotter]\n       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}